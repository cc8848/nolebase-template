- [大数据技术实战---项目中遇到的问题及项目经验_000X000的博客-CSDN博客](https://blog.csdn.net/ytp552200ytp/article/details/109359927)

**问题导读：
1、项目中遇到过哪些问题？
2、Kafka消息数据积压，Kafka消费能力不足怎么处理？
3、Sqoop数据导出一致性问题？
4、整体项目框架如何设计？**

**项目中遇到过哪些问题**

**7.1 Hadoop宕机**
（1）如果MR造成系统宕机。此时要控制Yarn同时运行的任务数，和每个任务申请的最大内存。调整参数：yarn.scheduler.maximum-allocation-mb（单个任务可申请的最多物理内存量，默认是8192MB）
（2）如果写入文件过量造成NameNode宕机。那么调高Kafka的存储大小，控制从Kafka到HDFS的写入速度。高峰期的时候用Kafka进行缓存，高峰期过去数据同步会自动跟上。

**7.2 Flume小文件**
Flume上传文件到HDFS时参数大量小文件?
调整hdfs.rollInterval、hdfs.rollSize、hdfs.rollCount这三个参数的值。

**7.3 Kafka挂掉**
（1）Flume记录
（2）日志有记录
（3）短期没事

**7.4 Kafka消息数据积压，Kafka消费能力不足怎么处理？**
（1）如果是Kafka消费能力不足，则可以考虑增加Topic的分区数，并且同时提升消费组的消费者数量，消费者数=分区数。（两者缺一不可）
（2）如果是下游的数据处理不及时：提高每批次拉取的数量。批次拉取数据过少（拉取数据/处理时间<生产速度），使处理的数据小于生产的数据，也会造成数据积压。

**7.5 Kafka数据重复**
  在下一级消费者中去重。（redis、SparkStreaming）

**7.6 Mysql高可用**
Hive的metadata存储在MySql中（配置MySql的高可用（主从复制和读写分离和故障转移））

**7.7 自定义UDF和UDTF解析和调试复杂字段**
自定义UDF（extends UDF 实现evaluate方法） 解析公共字段
自定义UDTF(extends Genertic UDTF->实现三个方法init(指定返回值的名称和类型)、process(处理字段一进多出)、close方法) -> 更加灵活以及方便定义bug

**7.8 Sqoop数据导出Parquet**
Ads层数据用Sqoop往MySql中导入数据的时候，如果用了orc（Parquet）不能导入，需转化成text格式

**7.9 Sqoop数据导出控制**
Sqoop中导入导出Null存储一致性问题：  
Hive中的Null在底层是以“\N”来存储，而MySQL中的Null在底层就是Null，为了保证数据两端的一致性。在导出数据时采用--input-null-string和--input-null-non-string两个参数。导入数据时采用--null-string和--null-non-string。

**7.10 Sqoop数据导出一致性问题**
当Sqoop导出数据到MySql时，使用4个map怎么保证数据的一致性
因为在导出数据的过程中map任务可能会失败，可以使用—staging-table –clear-staging

```coffeescript
sqoop export --connect jdbc:mysql://192.168.137.10:3306/user_behavior --username root --password 123456 --table app_cource_study_report --columns watch_video_cnt,complete_video_cnt,dt --fields-terminated-by "\t" --export-dir "/user/hive/warehouse/tmp.db/app_cource_study_analysis_${day}" --staging-table app_cource_study_report_tmp --clear-staging-table --input-null-string '\N'
```

`*复制代码*`任务执行成功首先在tmp临时表中，然后将tmp表中的数据复制到目标表中（这个时候可以使用事务，保证事务的一致性）

**7.11 SparkStreaming优雅关闭**
如何优雅的关闭SparkStreaming任务（将写好的代码打包，Spark-Submit）
Kill -9 xxx ?

开启另外一个线程每5秒监听HDFS上一个文件是否存在。如果检测到存在，调用ssc.stop()方法关闭SparkStreaming任务（当你要关闭任务时，可以创建你自定义监控的文件目录）

**7.12 Spark OOM、数据倾斜解决**

![img](https://img-blog.csdnimg.cn/20201029145052504.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3l0cDU1MjIwMHl0cA==,size_16,color_FFFFFF,t_70)


**项目经验**

**9.1 框架经验**
9.1.1 Hadoop
1）Hadoop集群基准测试（HDFS的读写性能、MapReduce的计算能力测试）
2）一台服务器一般都有很多个硬盘插槽（插了几个插槽）
如果不配置datanode.data.dir多目录，每次插入一块新的硬盘都需要重启服务器
配置了即插即用
3）Hdfs参数调优
Namenode有一个工作线程池，用来处理与datanode的心跳（报告自身的健康状况和文件恢复请求）和元数据请求  dfs.namenode.handler.count=20 * log2(Cluster Size)
4）编辑日志存储路径dfs.namenode.edits.dir设置与镜像文件存储路径dfs.namenode.name.dir尽量分开，达到最低写入延迟（提高写入的吞吐量）
5）YARN参数调优yarn-site.xml
（1）服务器节点上YARN可使用的物理内存总量，默认是8192（MB）
（2）单个任务可申请的最多物理内存量，默认是8192（MB）。
6）HDFS和硬盘空闲控制在70%以下。

9.1.2 Flume
\1)  Flume内存配置为4G（flume-env.sh修改）
\2)  FileChannel优化
通过配置dataDirs指向多个路径，每个路径对应不同的硬盘，增大Flume吞吐量。
checkpointDir和backupCheckpointDir也尽量配置在不同硬盘对应的目录中，保证checkpoint坏掉后，可以快速使用backupCheckpointDir恢复数据
\3)  Sink：HDFS Sink小文件处理
这三个参数配置写入HDFS后会产生小文件，hdfs.rollInterval、hdfs.rollSize、hdfs.rollCount

9.1.3 Kafka
\1)  Kafka的吞吐量测试（测试生产速度和消费速度）
\2)  Kafka内存为6G（不能超过6G）
\3)  Kafka数量确定：2 * 峰值生产速度（m/s）* 副本数 / 100 + 1 = ?
\4)  Kafka中的数据量计算
每天数据总量100g(1亿条)  10000万/24/60/60 = 1150条/s
平均每秒钟：1150条
低谷每秒：400条
高峰每秒钟：1150 * 10 = 11000 条
每条日志大小： 1K左右
每秒多少数据量：20MB
\5)  Kafka消息数据积压，Kafka消费能力不足怎么处理？
（1）如果是Kafka消费能力不足，则可以考虑增加Topic的分区数，并且同时提升消费组的消费者数量，消费者数=分区数。（两者缺一不可）
（2）如果是下游的数据处理不及时：提高每批次拉取的数量。批次拉取数据过少（拉取数据/处理时间<生产速度），使处理的数据小于生产的数据，也会造成数据积压。

9.1.4 MySql之元数据备份
元数据备份（重点，如数据损坏，可能整个集群无法运行，至少要保证每日零点之后备份到其它服务器两个复本）

9.1.5 Sqoop参数
1）Sqoop导入导出Null存储一致性问题
2）Sqoop数据导出一致性问题
–staging-table方式 --clear-staging
3）Sqoop数据导出的时候一次执行多长时间
Sqoop任务5分钟-2个小时的都有。取决于数据量。

9.1.6 Azkaban每天执行多少个任务
（1）每天集群运行多少job?
（2）多个指标（200）*6=1200（1000-2000个job）
（3）每天集群运行多少个task? 1000*（5-8）=5000多个
（4）任务挂了怎么办？运行成功或者失败都会发邮件
Zip a.job b.job c.job  job.zip 把压缩的zip包放到azkaban的web界面上提交（指定sechduler）