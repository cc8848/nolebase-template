- [HDFS的数据存储、压缩、纠删码及节省存储的方法_java编程艺术的博客-CSDN博客](https://blog.csdn.net/penriver/article/details/118935451)

# 1 数据分块存储+副本的策略

数据分块存储+副本的策略是[HDFS](https://so.csdn.net/so/search?q=HDFS&spm=1001.2101.3001.7020)保证可靠性和性能的关键，原因如下：

- 文件分块存储之后按照数据块来读，提高了文件随机读的效率和并发读的效率；
- 保存数据块若干副本到不同的机器节点实现可靠性的同时也提高了同一数据块的并发读效率；
- 数据分块是非常切合MapReduce中任务切分的思想

# 2 副本存放策略

通常情况下，当复制因子为3时，HDFS的放置策略如下：

- 如果writer在datanode上，在本地机器上放置一个副本，否则在与writer相同机架的datanode上随机选择一个放置一个副本
- 在另一个(远程)机架上的datanode上放置一个副本
- 最后一个副本放置在同一个远程机架的不同datanode上
- 如果复制因子大于3，那么第4个和接下来的副本的位置是随机确定的，同时保持每个机架的副本数量低于上限((副本- 1)/机架+ 2)。
- 因为NameNode不允许datanode在同一块上有多个副本，所以创建的最大副本数是该时刻datanode的总数。

这种策略**减少机架间写流量，提高写性能**。机架的错误远远比节点的错误少，所以这种策略不会影响到数据的可靠性和可用性。因为数据块只存放在两个不同的机架上，所以此策略**减少了读取数据时需要的网络传输总带宽**。在这种策略下，副本并不是均匀的分布在不同的机架上：三分之一的副本在一个节点上，三分之二的副本在一个机架上，其它副本均匀分布在剩下的机架中，这种策略在不损害数据可靠性和读取性能的情况下改进了写的性能。

详见：[HdfsDesign Block Placement Policies](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)

# 3 存储压缩方式

目前hdfs集群有多种存储压缩方式：gzip、bzip2、lzo、lz4、snappy等

| 压缩格式 | split | native | 压缩率 | 速度   | 是否hadoop自带 | linux命令 | 应用程序是否需要修改           |
| -------- | ----- | ------ | ------ | ------ | -------------- | --------- | ------------------------------ |
| gzip     | 否    | 是     | 很高   | 比较快 | 是，直接使用   | 有        | 和文本处理一样，不需要修改     |
| lzo      | 是    | 是     | 比较高 | 很快   | 否，需要安装   | 有        | 需要建索引，还需要指定输入格式 |
| snappy   | 否    | 是     | 比较高 | 很快   | 否，需要安装   | 没有      | 和文本处理一样，不需要修改     |
| bzip2    | 是    | 否     | 最高   | 慢     | 是，直接使用   | 有        | 和文本处理一样，不需要修改     |

适用场景

- gzip：当每个文件压缩之后在128M以内的（1个块大小内），如一天或者一个小时的日志压缩成一个gzip 文件，运行mapreduce程序的时候通过多个gzip文件达到并发。
- lzo: 一个很大的文本文件，压缩之后还大于200M以上的可以考虑，而且单个文件越大，lzo优点越越明显, 但需要创建索引
- snappy： 当mapreduce作业的map输出的数据比较大的时候，作为map到reduce的中间数据的压缩格式；或者作为一个mapreduce作业的输出和另外一个mapreduce作业的输入
- bzip2: 适合对速度要求不高，但需要较高的压缩率的时候：

1. mapreduce作业的输出格式；
2. 输出之后的数据比较大，处理之后的数据 需要压缩存档减少磁盘空间并且以后数据用得比较少的情况；
3. 对单个很大的文本文件想压缩减少存储空间，同时又需要支持split，而且兼容之前的应用程序的情况

# 4 HDFS纠删码（Erasure Coding）

参见[HDFS Erasure Coding](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HDFSErasureCoding.html)

HDFS默认的3副本策略，在存储空间和其他比如网络带宽上有200%的开销，因而副本策略是昂贵的。但是对于具有相对较低I/O的冷热数据集，在正常操作期间很少访问其他副本块，但仍然消耗与第一个副本相同的资源量。

纠删码是CDH6/Hadop3引入的新功能，使用纠删码（Erasure Code，EC）来替换副本策略。纠删码提供了与副本相同的容错能力，但使用较少的存储空间。

在存储系统中，EC最显着的用途是廉价磁盘冗余阵列（RAID）。 RAID通过条带化实现EC，条带化将逻辑上连续的数据（例如文件）划分为较小的单元（例如位，字节或块），并将连续的单元存储在不同的磁盘上。将这种条带分布的单位称为条带化单元（或单元）。对于原始数据单元的每个条带，都会计算并存储一定数量的奇偶校验块，这个过程称为编码。可以通过剩余数据块和奇偶校验块的解码计算来恢复任何条带单元上的错误。

将EC与HDFS集成可以提高存储效率，同时提供与副本相同的容错能力。例如6份原始数据，编码后生成3份校验数据，一共9份数据，只要最终有6份数据存在，就可以得到原始数据，它可以容忍任意3份数据不可用，而冗余的空间（3）只有原始空间（6）的0.5倍，只有副本方式（6*3-6=12）的1/4，因此，可以节约更多的空间成本。注意：使用

与副本相比，纠删码的优点在于节省存储空间,缺点在于有计算开销而且修复需要一定时间，而副本损失只要复制出来损失的数据，未损失的数据可以继续提供服务。

## 4.1 纠删码的劣势

- 网络带宽的消耗，因为数据恢复需要去读其他的数据块和校验块
- 进行编码，解码计算需要消耗CPU资源

## 4.2 纠删码的适用场景：

- 对于I/O活动相对较低的温数据集和冷数据集，在正常操作期间很少访问额外的块副本，但仍然消耗与第一个副本相同数量的资源
- 温冷数据集群基本稳定，耗资源量少，所以一旦进行数据恢复，将不会对集群造成大的影响

# 5 hdfs 节省存储的方法

- 将温、冷数据集转移到冷的hdfs集群，冷的hdfs集群启动纠删码
- 将大量小文件合并，并按天或小时归档，如spark streaming实时采集的日志，数据分布不太均匀，大的有5个G，小的只有几十MB
- 针对文件使用压缩存储，如采用lzo或snappy压缩
- 针对文件使用OrcFile或parquet存储，不使用文件文件存储
- 删除业务上的一些临时表
- 删除业务上的无用数据