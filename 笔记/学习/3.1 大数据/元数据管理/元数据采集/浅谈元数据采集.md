- [浅谈元数据采集 | StartDT Tech Lab 10 (qq.com)](https://mp.weixin.qq.com/s/7jW3wiwJIFLCBQQzr8nclA)

**元数据是描述数据的数据。**元数据通常包含数据的基本信息和数据血缘信息。

实际业务场景中，业务人员面临数据出现问题后，需要评估影响范围、定位问题环节及责任人的情况。

基于元数据，可分析得到上游问题表、调度任务、下游影响表、影响范围。基于这种有效的评估，企业能更高效地对企业数据资产进行管理。

# **一、概述**

元数据采集可以分为外部系统元数据采集、元数据血缘关系采集，它们都围绕Meta对象体系展开。（如下图所示）

![图片](https://mmbiz.qpic.cn/mmbiz_png/qGYk2KicXmWsEjLcMTcObn6Fs6FZeKUApxs6l16wE3aukf1WsXtrSPTdzw4EFqyp4kVH8bp4RBwuZmB5eEicdtsQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

架构图

图源：元善

Meta对象体系：Meta对象体系是一系列设计良好的元数据API和数据结构，其具备屏蔽复杂特性的能力，可以抽象共性操作。它应用于整个元数据周期，例如：采集期间、分析期间等。所有的元数据行为都围绕它们进行。

外部系统元数据采集：应用于外部元数据至Simba元数据的过程。因外部系统存在不同的数据源，其具有特有的访问、存储、序列化等形式。所以我们需要针对不同数据源解析得到有价值的共性信息(例如字段序号、名称、类型、说明等)，将其转换为规范统一的内部元数据形式。

元数据血缘关系采集：数据经过一系列的调度任务，会生成错综复杂的元数据关系，比如源表、源字段、调度任务、责任人、目标表、目标字段、指标等，我们将这些数据通过Meta对象体系采集存储，为进一步的分析做准备。

下面我们会针对每一个主要模块，简要介绍技术和设计。

# **二、Meta对象体系**

采集元数据首先要设计良好的API规范，我们首先定义了抽象的分区、表、字段、拓展等元数据对象体系，通过不同的数据源Parse解析器，解析成抽象的元数据对象，所有操作围绕对象体系进行。

![图片](https://mmbiz.qpic.cn/mmbiz_png/qGYk2KicXmWsEjLcMTcObn6Fs6FZeKUApianfgmq1eFRw0JdjFeZ1fwxEVicia1CSf3zKXIjicWSUCJrpXpbyC9JCYg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

采集外部元数据-结构图

图源：元善

- MetaPartition

**分区元数据**，包含分区数量、分区字段等信息。

- MetaTable

**表元数据**，包含DB名、表名、表ID、分区标识、创建时间等信息。数据治理通常围绕它展开，也是获得MetaColumn的先决条件。

- MetaColumn

**字段元数据**，包括名称、类型、注释、是否分区字等字段信息。它在数据同步映射、数据指标、数据血缘中都起到重要作用。

- MetaExtend\

**扩展元数据**，我们可以通过扩展元数据来支持对更多通用属性的支持，例如总存储、索引大小、访问频次等，这可以帮助我们更好的治理数据。

# **三、外部元数据采集**

对于不同数据源，元数据存储的形式各不相同，对于不同数据源的解析，核心在于定位元数据结构、存储位置。我们以字段元数据（MetaColumn）为例：

- MySQL Meta Parse

MySQL字段元数据信息主要存储在information_schema.columns，其中ORDINAL_POSITION、COLUMN_NAME、DATA_TYPE、COLUMN_COMMENT、TABLE_SCHEMA、TABLE_NAME属于关键字段，含义分别是序号、字段名、数据类型、说明、库名、表名。

- Oracle Meta Parse\

Oracle字段元数据信息主要存储在ALL_TAB_COLUMNS、ALL_COL_COMMENTS中，其中ALL_TAB_COLUMNS.COLUMN_ID、ALL_TAB_COLUMNS.COLUMN_NAME、ALL_TAB_COLUMNS.DATA_TYPE、ALL_COL_COMMENTS.COMMENTS、ALL_TAB_COLUMNS.TABLE_NAME、ALL_TAB_COLUMNS.OWNER属于关键字段，含义分别是序号、字段名、数据类型、说明、表名、所有者。

- Postgresql Meta Parse

Postgresql字段元数据信息主要存储在PG_CLASS、PG_ATTRIBUTE、PG_TYPE、PG_NAMESPACE、PG_DESCRIPTION，其中PG_ATTRIBUTE.ATTNUM、PG_ATTRIBUTE.ATTNAME、PG_TYPE.TYPNAME、PG_DESCRIPTION.DESCRIPTION、PG_CLASS.RELNAME、PG_NAMESPACE.NSPNAME属于关键字段，含义分别是序号、字段名、类型、说明、表名、名空间。

- Impala Meta Parse

Impala字段元数据信息，可以通过执行“DESCRIBE {表名}”SQL获得。其中NAME(1)、TYPE(2)、COMMENT(3)属于关键字段，含义分别是字段名、类型、含义。

- Hive Meta Parse\

Hive字段元数据信息，可以通过多种方式读取元数据，例如直接通过SQL读取MySQL元数据、通过HIVE "DESCRIBE FORMATTED"命令集、IMetaStoreClient API。我们着重讲解MySQL元数据存储结构，主要存储在DBS、TBLS、COLUMNS_V2其中关键字段COLUMNS_V2.COLUMN_NAME、COLUMNS_V2.TYPE_NAME、COLUMNS_V2.COMMENT、COLUMNS_V2.INTEGER_IDX、DBS.NAME、COLUMNS_V2.TBL_NAME，含义分别是字段名、类型、含义、序号、库名、表名。

- Elasticsearch Meta Parse

Elasticsearch字段元数据信息，可以通过JestClient执行对单表查询语句获得。Elasticsearch采用JSON结构定义表、字段元数据信息。通过解析JSON中mappings字段获得对每个字段的JSON对象，其中KEY、TYPE、INDEX是关键字段，含义分别是字段名、类型、序号。

# **四、元数据血缘关系采集**

DataSimba中的数据血缘信息，往往源于解析生产数据所用的SQL等作业。这里以大数据处理中最常用的离线计算引擎Hive为例，介绍如何通过解析作业的SQL脚本获取数据血缘信息。其他各类计算引擎，例如SparkSQL和FlinkSQL，原理上大同小异。

当收到类似下面的Hive SQL语句

```
SELECT id, name from t_user where status = 'active' and age > 18
```

HIVE的处理过程如下：

## 01. 语法分析

使用Antlr将SQL语句解析成抽象语法书(AST)，例如:

![图片](https://mmbiz.qpic.cn/mmbiz_png/qGYk2KicXmWsEjLcMTcObn6Fs6FZeKUApyGzOBV9JXAC7D4NNX0lhfhOJxGAhuI75jamsK5g6LVrwe3zOVXaVZQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

图源：元善

## 02. 语义分析

验证SQL语句中表名、列表、数据类型和隐式转换，以及Hive提供的函数和用户定义函数(UDF/UAF)；以及元数据绑定，会从Hive数据库中查询相关元信息，将符号绑定到源表的字段。

## 03. 逻辑计划生成

生成逻辑计划，简单理解就是在单机中可以按照顺序执行抛出结果的计算计划。

## 04. 逻辑计划优化

对算子数进行优化，不改变执行结果的前提下，优化执行计划。常见的例如PartitionPrune，在Hive中定义了分区表，Where条件也出现了分区字段，那么执行时只扫描该分区数据。

## 05. 物理计划生成

将逻辑计划生成包含由MapReduce任务组成的DAG物理计划(Tez、Spark)。会将逻辑计划拆解，生成Mapper和Reducer不同的步骤。

## 06. 分布式物理计划执行

将DAG发送到Hadoop集群执行。

在上面Hive工作流程-语法分析步骤，我们可以通过对AST遍历，得到哪些是输入表，哪些是输出表。例如以下SQL：

```
insert overwrite table over_tmp select id, age, name from tmp;输入表: tmp, 输出表: over_tmp
```

Hive中提供静态血缘解析的支持，通过LineageInfo.getInputTableList() 和LinegeInfo.getOutputTable() 分别可以获得输入表、输出表。

Hive同时也提供支持动态血缘解析，HiveHook拦截Hive执行过程，动态获得关系。血缘采集HiveHook运行于Post-execution hooks过程。在查询执行完成之后以及将结果返回给用户之前调用。我们可以将源表、目标表、源字段、目标字段以及它们的关系发送至MQ，通过集群消费者订阅血缘数据至存储介质。

至此，我们通过本章的学习，简单了解了如何采集外部元数据、构建内部元数据、以及基于Hive的静态/动态血缘采集。当然元数据及以元数据为基础的数据分析，不仅止于此，我们会在之后的学习中继续深入探讨。