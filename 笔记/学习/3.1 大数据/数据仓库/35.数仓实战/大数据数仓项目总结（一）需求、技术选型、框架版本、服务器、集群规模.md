- [大数据数仓项目总结（一）需求、技术选型、框架版本、服务器、集群规模_PassionZheng的博客-CSDN博客_列举数仓技术组件选型](https://blog.csdn.net/select_alter_drop/article/details/105623988)

# 一.需求描述

数据仓库( Data Waehouse ) 是为企业所有决策制定过程，提供所有系统数据支持的战略集合。通过对数据仓库中数据的分析，可以帮助企业，**改进业务流程、控制成本、提高产品质量**等。

数据仓库，并不是数据的最终目的地，而是为数据最终的目的地做好准备。这些准备包括对数据的：**清洗，转义，分类，重组，合并，拆分，统计**等等。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200419223332428.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NlbGVjdF9hbHRlcl9kcm9w,size_16,color_FFFFFF,t_70)

### 1）项目大致需求

- 1）**用户行为数据**采集平台搭建
- 2）**业务数据**采集平台搭建
- 3）数据仓库**维度建模**
- 4）分析，用户、流量、会员、商品、销售、地区、活动等电商**核心主题**
- 5）采用**即席查询**工具，随时进行指标分析
- 6）对**集群性能进行监控**，发生异常需要报警。
- 7）**元数据管理**
- 8）**质量监控**

### 2）需考虑的问题

- 1）项目**技术如何选型**?
- 2）**框架版本**如何选型？(Apache、 CDH、HDP)
- 3）服务器使用**物理机还是云主机**?
- 4）如何确认**集群规模**? (项目的数据规模计算)

# 二.项目框架及选型

## 1.技术选型

1）技术选型主要考虑因素：

- **业务需求**
- **数据量大小**
- **行业内经验、技术成熟度**
- **开发维护成本**
- **总成本预算**

**2）可选择技术：**

- **数据采集传输: Flume，Kafka，Sqoop**，Logstash， DataX
- **数据存储: MySql，HDFS，HBase**，Redis，MongoDB
- **数据计算: Hive，Spark，Flink，Tez，** Storm
- 数据查询: **Presto，Kylin，Impala，Druid**
- 数据可视化: Echarts、 Superset、QuickBI、DataV
- **任务调度: Azkaban**、 Oozie .
- **集群监控:Zabbix**
- **元数据管理: Atlas**

## 2.项目架构与数据流程

![基础架构](https://img-blog.csdnimg.cn/20200419223446392.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NlbGVjdF9hbHRlcl9kcm9w,size_16,color_FFFFFF,t_70)

系统数据处理流程：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200429081959344.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NlbGVjdF9hbHRlcl9kcm9w,size_16,color_FFFFFF,t_70)

数据仓库的输入数据源和输出系统分别是：

- 输入系统：埋点产生的用户行为数据、JavaEE后台产生的业务数据
- 输出系统：报表系统、用户画像系统、推荐系统

## 3.框架版本选择

### 1）Hadoop发行版本选择

**Hadoop三大发行版本Apache/CDH/HDP如何选择？**

- a）Apache: 开源、稳定、使用较多；但运维麻烦，组件间兼容性需要自己调研 **(建议使用)**
- b）CDH: 国内使用最多的版本，但CM不开源，并且开始要收费，一个节点1万美金
  - Cloudera Manager是一个拥有集群自动化安装、中心化管理、集群监控、报警功能的一个工具（软件）,使得安装集群从几天的时间缩短在几个小时内，运维人员从数十人降低到几人以内，极大的提高集群管理的效率。
- c）HDP:开源，可以进行二次开发，但是没有CDH稳定，国内使用较少

### 2）Apache框架版本具体型号

| 产品      | 版本                |
| --------- | ------------------- |
| Hadoop    | 2.7.2、 **3.1.3**   |
| Flume     | 1.7.0、 **1.9.0**   |
| Kafka     | 0.11.0.2、**2.4.1** |
| Hive      | 2.3、**3.1.2**      |
| Spark     | **2.4.5**           |
| Sqoop     | **1.4.6**           |
| MySQL     | **5.7.29**          |
| Azkaban   | 2.5.0               |
| Java      | **1.8**             |
| Zookeeper | 3.4.10、**3.5.7**   |
| Kylin     | **3.0.1**           |
| HBase     | **2.2.4**           |
| Presto    | **0.196**           |

注意事项：框架选型尽量不要选择最新的框架，选择**最新框架半年前左右的稳定版**。

## 4.服务器选型

服务器选择物理机还是云主机?

1)物理机成本：

- 硬件成本：
  - **配置：以128G内存，20核物理CPU，40线程，8THDD和2TSSD硬盘，**
  - 单价：戴尔品牌——单台报价**4W出头**
  - 寿命：一般物理机**寿命5年左右**
- 运维成本：需要有专业的运维人员，平均一个月1万
- 其他费用：电费、场地、空调等——**配套成本**

2)云主机成本：

- 硬件成本：以阿里云为例，差不多相同配置，每年5W。
- 运维成本：很多运维工作都由阿里云完成，运维相对较轻松

3)企业如何选择：主要考虑企业数据规模、发展预期、资金实力、业务属性等

- 资金充裕且和阿里没有直接冲突的公司：如金融有钱公司——选择阿里云
- 中小公司（短期）为了融资上市——选择阿里云，拉到融资后买物理机
- 有长期打算，资金比较足的公司——选择物理机

## 5.集群资源规划设计

1.如何确定集群规模

- 首先要考虑自己单台服务器的性能，
- 其次要考虑的是每日的数据规模：每日活跃用户、用户平均每日数据量
- 副本策略：一般2~3个副本
- 扩容周期：半年不扩容
- 预留空间：一般20%~30%
- 数仓分层

**假设每台服务器配置：128G内存，20核物理CPU，40线程，8THDD和2TSSD硬盘：**

**简单版：**

- 一天日活用户：100万
- 一人一天数据：100条
- 一条日志大小：1 K左右
- 一天数据：1 亿条
- 半年数据：100G * 180天 ≈ 18T
- 副本数据：18T*3=54T
- 预留20%-30%大小：54T/0.7=77T
- 结论：8T*10台服务器

**考虑数仓分层、压缩、副本策略等其他各项：**

- 1)每天用户行为数据规模：以**每天日活跃用户100万，每人一天平均100条日志数据，每条日志大小1K**，则
  100 万 ∗ 100 条 ∗ 1 K / 1024 / 1024 = 约 100 G / 天 100万*100条*1K/ 1024/ 1024=约100G/天100万∗100条∗1K/1024/1024=约100G/天
- 2）Hive数仓分层：
  - ods与dwd层：采用LZO压缩+列式存储，每天100G数据压缩存储后两层共计：10 G ∗ 2 = 20 G
  - dws层聚合不压缩：50G
  - 再加上HDFS分布式存储的3个副本，共计：

70 G ∗ 3 = 210 G

- 3)半年内不扩容服务器来算：210 G ∗ 180 天 = 约 37 T
- 4)预留20%~30%Buf：37 T / 0.7 = 53 T
- 5)kafka中：每天100G数据，两个副本，预留7天，预留30%空间100 G ∗ 2 ∗ 7 / 0.7 = 2 T
- 6)flume忽略不计
- 7)业务数据：
  - 按照每天下单10万，每人每天10条，每条1K：10 万 ∗ 10 ∗ 1 K / 1 0 6 = 1 G 10万*10*1K/10^6=1G10万∗10∗1K/106=1G
  - 算上3层数仓存储、3个副本、180天扩容周期、30%预留

1 G ∗ 3 层 数 仓 ∗ 3 副 本 ∗ 180 天 / 0.7 = 约 2 T 1G*3层数仓*3副本*180天/0.7=约2T1G∗3层数仓∗3副本∗180天/0.7=约2T

- 7）日志数据存储周期30天：100 G ∗ 30 = 3 T 100G*30=3T100G∗30=3T
- 8）共计 53+2+2+3=60T
- 结论：大致需要8T*8台服务器

## 6.测试集群规划

需要考虑的问题：

1、测试服务器多少台;

2、测试环境什么样;

3、测试数据哪里来;

4、如保证写的SQL正确:

5、测试之后如何上线

测试集群规划：

- 尽量将耗内存的服务分开安装
- 客户端服务放到一起
- Flume与Kafka安装对应起来

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200604112349618.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NlbGVjdF9hbHRlcl9kcm9w,size_16,color_FFFFFF,t_70)

另外还需要考虑的问题：

1、实现一个需求需要多长时间;

2、项目三年内迭代

3、当前版本是多少;

4、每天做什么