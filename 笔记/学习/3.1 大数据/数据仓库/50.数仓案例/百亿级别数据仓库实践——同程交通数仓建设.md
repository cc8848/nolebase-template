- [百亿级别数据仓库实践——同程交通数仓建设 (qq.com)](https://mp.weixin.qq.com/s/BGMQ_V-h6OQF4N2MpPb-7A)

交通事业部成立以来，业务量以惊人的速度增长，增值创新业务也是遍地开花，作为业务支撑的数据仓库自然也经历了两次大的迭代升级。交通事业部对数据应用比较重视，相信数据能驱动业务增长，同时交通目前的数据量级已经来到了PB级别，每天以10T的数量增长，因此对数据仓库的扩展性、稳定性、易用性等有了更高的要求。对此，我们采取了分层次、分主题的数据仓库结构，主流技术与多项技术搭配的ETL结构，搭建了交通的数据仓库，本文将分为技术架构和业务架构来给大家讲解一下交通的数据仓库建设过程。

初级阶段的思路是业务优先，数据仓库架构变现从简。因为这个时期内业务的方向和过程都处于灵活多变阶段，如果此时耗费大量时间去做底层数据仓库设计，那么就无法及时响应业务诉求，不能快速做出决策，所以只有在满足快速支撑业务的情况下才会进行数据仓库的架构设计。此阶段虽然是以变现为主，但是数据仓库的架构要先行。

最早的交通事业部（原火车票事业部）只有火车票一个主流产品，数据量还不到现在的百分之一。以当时的体量，我们并不需要花费大量精力打造数据仓库，只要能将数据汇聚到一起做些数据分析即可，一切为了提升服务业务的能力。刚开始的数据部门雏形是两位会写SQL的数据分析师从一台商业数据库 服务器上抽取数据进行分析，这很好的解决了业务需求。此方案的弊端是数据没有任何加工，数据类型杂乱无章，字段缺省值较多，查询统计效率低下（OLTP计划模式）等因素，导致分析师每天的工作效率无法得到提升。随着数据量的增长，业务的增加，数据源的多样化，用一台数据库服务器已经远远不能满足需求。因为业务在快速发展，事业部对数据应用的要求同样开始多样化，对获取数据的便捷性和效率也有了一定的要求，因此催生了交通事业部第一代的数据仓库。如下图所示：

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/uroKbD3UGVT0iaERyiae5nogjoccwBCcIfzjicKW0IDk1uPwWAGJQa2WkPymanz9rXGB2FmQ87vHDyHQI77SUcGvQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

第一代数据仓库的设计背景是数据量在1T左右，每日增量10G。经过多方研究和综合考虑，我们采取了微软的BI工具组件(SSIS + 数据库 + CDC)。数据更新频率为T+1天增量的方式，团队利用微软的系列工具快速完成数据的ETL开发，搭建了一套轻量级的数据仓库。当然，我们在利用SSIS做ETL的过程中也实现了开发模板化，监控体系化，并实现了一套简单的血缘依赖和重试机制用来调度每天的任务。通过调整调度频率，实现了离线和准实时两套应用体系。至此为止，已经很好的解决了火车票看数据的需求，并实现了简单的应用推荐等。

利用微软的一系列工具确实能快速构建数据仓库，但是毕竟单台服务器存储能力有限，就算我们做了存储集群，也依然面临数据量过大导致的一些问题。当时最长的清洗任务已经超过4小时，一旦出现小问题，很难保证在8点前完成数据的清洗。然而数据量增长带来的问题永远不会只有一个，任务量增加导致的清洗时间变长，表的频繁修改导致死锁，资源的争用导致任务停滞等等，这些问题都一一来临，任务维护几乎都苦不堪言。因此我们与公共数据中心合作，利用他们的大数据平台技术集群搭建了交通的第二代数据仓库。如下图所示：

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/uroKbD3UGVT0iaERyiae5nogjoccwBCcIfc08fkl4dDtaSeJyvo3dibCDbQyZ14fpVdMVibgIMDYlaxibMK8wuhUghw/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

为了应对数据量的增长，交通的业务库架构也越来越复杂，经历了2次大的升级迁移，采用了多种集群多种数据库混合的架构，这使得ETL的工作十分的复杂多变，数据源多达10多种，数据抽取技术各不相同，因此形成了以SQOOP为主，KAFKA、MQ、API、XDATA、FLUME、STORM、SSIS等多种技术混合使用的架构来将数据抽取汇总到集群的ODS层，再去进行大量离线清洗的ETL方案。这套架构很好的解决了第一代数据仓库中遇到的问题，并提供了更好的扩展性。

在得到数据中心的大力支持后，目前支撑的数据总量来到了PB级别，每日的增量大约在10T左右。面对如此巨大的数据量，每天的ETL清洗并不轻松，全量的数据清洗同样会大量消耗集群资源，造成任务的delay。因此在充分了解交通的业务特点和数据特点后，我们采取了全量，增量和准实时共存的清洗流程。业务上除了订单系列表会进行大量更新外，数据量较大的基本都是日志数据，日志数据的特点就是只有插入，因此在ETL过程中我们对日志采取了按天增量分区的方式进行同步清洗，而订单系列则根据业务特点（四个月外的数据不会发生变化）采用六个月增量更新的方式来缩短每天的ETL过程，并利用数据统计的特点（T+1基本都是统计昨日变化的数据，任务占比超过80%）创建更多的小表和大表来降低hadoop集群资源的消耗。因此虽然目前交通的数据量相对较大，但是ETL的效率依然很高。

在这样的架构下交通已经实现了多个项目（火车票，地面交通，国际用车，国际火车票，船票）数据的聚合和清洗工作，为解决数据获取和分析提供了有力保障。在此架构基础上，我们团队也进行一系列的数据挖掘应用项目，成功的实现了余票提醒、智能推荐、中转推荐、交叉推荐、智慧交通等多种离线实时结合的数据应用，为未来大交通的商业智能发展提供了基础保障。

原先的业务结构很简单，相应的逻辑也不复杂，业务主题也还没有成型（因为业务变化过快，花费精力标准建模维护的成本较高），因此开始并没有按照数据仓库的理论建立业务集市，而是将重心放在了业务统计的效率上，直接由轻度清洗的明细数据产生汇总的应用数据，用于数据展示，业务报告等。

第二代数据仓库中可以看到数据层次达到了五层，因为需要兼容各个部门的使用，数据中心已经做了一次数据仓库三层架构的建立，而FACT层则是给到我们交通去使用的明细数据层，在此之上我们又根据业务主题划分建立了CUBE层（数据集市层，2016年年末），用来支撑上层业务，提高易用性和扩展性，然后到达应用层。



![图片](https://mmbiz.qpic.cn/mmbiz_jpg/uroKbD3UGVT0iaERyiae5nogjoccwBCcIf7xmpMR1N81A2lQBia4GHdvlUVAzWiczAlppfEpyEh92rGWPibhNVWW8Rg/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

2016年是业务爆发年，年末订单增长到了年初的四倍，并且主营业务基本成型，相应的指标维度大多已经确定，因此在年末按照星型模型创建了火车票订单、票量、营收、会员、流量、供应商、运营活动等业务主题集市，增加了主题集市层（cube层）。而随着创新业务的不断增长，业务之间的耦合度增加，为了数据仓库的易用性和扩展性，我们将主题集市星型模型改成了雪花模型，增加业务间耦合度，可以更好的支持业务的多维分析，下钻探索，纵观大局等各种各样多变的需求。

目前交通的数据仓库已经成型，不过依然还有很多很多的事情需要去做，比如自动化数仓，数据交换平台，数据治理平台，数据安全建设，实时数据平台，智能推荐平台，自助多维分析甚至机器学习平台等。未来交通的数据仓库将会继续为业务服务，随着业务的发展，将更多的要求数据的准确性，安全性，覆盖面，时效性和简易性。数据的模型稳定，数据质量的治理，基础数据的维护，数据的全面覆盖将加大力度来保证数据的准确性，未来数据的重要性不言而喻，准确全面的数据才是正确决策的基础。未来的世界同样瞬息万变，决策需要不断地随着数据而改变，但是数据价值是会衰减的，因此数据的时效性将决定了数据的价值高低。未来的世界同样是人人都会数据分析的时代，数据仓库的用户对象将由专业的技术人员变成越来越多的小白用户，数据仓库的简单易用也将是未来的发展趋势。